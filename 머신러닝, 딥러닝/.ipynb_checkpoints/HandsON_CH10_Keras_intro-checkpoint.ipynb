{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985db4fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong><font color=\"blue\" size=\"3em\">10. 케라스 기초</font></strong><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d0cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 20:56:19.774962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-29 20:56:19.774994: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740707a8",
   "metadata": {},
   "source": [
    "##### 시퀀셜 API 사용해 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a0841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb4330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3468ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163c7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split & use scaler\n",
    "X_valid, X_train, = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e276a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef73782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289f4d2",
   "metadata": {},
   "source": [
    "##### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0157ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 19:26:41.362058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-26 19:26:41.362098: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-26 19:26:41.362117: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (second): /proc/driver/nvidia/version does not exist\n",
      "2021-11-26 19:26:41.362440: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential() # 순서대로 연결된 층을 일렬로 쌓아서 구성하는 모델\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) # flatten 입력 이미지를 1D 배열로 변환, 사실 자동으로 구성됨\n",
    "model.add(keras.layers.Dense(300, activation='relu')) # 뉴런 300개의 Dense 은닉층을 추가/ relu활성화함수 사용\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # 배타적인 클래스이므로 소프트맥스 활성화함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7268cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같음\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd45398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 모든 뉴런이 연결되어 있으므로 param은 다음과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d627a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x7fa4bd03fee0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa4bfe44730>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa4bfe638b0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa4bd048040>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 층의 리스트를 출력할 수 있음\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c21010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7fa4bfe44730>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스나 이름으로 층을 선택할 수 있음\n",
    "hidden1 = model.layers[1]\n",
    "hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a117c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2096ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d6278b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02850835 -0.05529347 -0.06893588 ... -0.00421687 -0.07249486\n",
      "  -0.03826016]\n",
      " [-0.06578077  0.06521367 -0.01140849 ...  0.02212026  0.06934319\n",
      "  -0.01582282]\n",
      " [ 0.04900348  0.02386917  0.00767882 ...  0.00493672 -0.03504289\n",
      "   0.04594538]\n",
      " ...\n",
      " [ 0.01440104 -0.02769695 -0.02751329 ...  0.0137969  -0.00243835\n",
      "  -0.07273527]\n",
      " [-0.02974964  0.04935531 -0.07403637 ... -0.04494701 -0.03354308\n",
      "  -0.02630302]\n",
      " [-0.05834828  0.00950275 -0.01136702 ...  0.04805686  0.0522968\n",
      "   0.03324996]]\n",
      "(784, 300)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# 층의 파라미터에 get_weights()로 접근 가능\n",
    "w, b = hidden1.get_weights()\n",
    "print(w)\n",
    "print(w.shape)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f0d30",
   "metadata": {},
   "source": [
    "##### 모델 컴파일\n",
    "- 모델 생성 후, compile() 매서드로 손실함수와 옵티마이저를 지정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdaf28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd', # 경사하강법을 사용하여 모델을 훈련한다는 의미\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7985f",
   "metadata": {},
   "source": [
    "- 클래스가 배타적이므로 sparse_categorical_crossentropy 손실 사용\n",
    "- 만약 샘플마다 클래스별 타깃 확률을 가지고 있다면, categorical_crossentropy 손실을 사용해야 함\n",
    "- 이진 분류나 다중 레이블 이진분류라면 출력층에 softmax 대신 sigmoid함수를 사용하고 binary_crossentrophy손실을 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8f316c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7187 - accuracy: 0.7642 - val_loss: 0.5517 - val_accuracy: 0.8024\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4882 - accuracy: 0.8296 - val_loss: 0.4581 - val_accuracy: 0.8434\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.8451 - val_loss: 0.4206 - val_accuracy: 0.8552\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4152 - accuracy: 0.8543 - val_loss: 0.4036 - val_accuracy: 0.8632\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3952 - accuracy: 0.8609 - val_loss: 0.3819 - val_accuracy: 0.8688\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3777 - accuracy: 0.8676 - val_loss: 0.3737 - val_accuracy: 0.8734\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3641 - accuracy: 0.8706 - val_loss: 0.3569 - val_accuracy: 0.8724\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3520 - accuracy: 0.8749 - val_loss: 0.3579 - val_accuracy: 0.8734\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3407 - accuracy: 0.8787 - val_loss: 0.3503 - val_accuracy: 0.8800\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3320 - accuracy: 0.8800 - val_loss: 0.3609 - val_accuracy: 0.8692\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3227 - accuracy: 0.8834 - val_loss: 0.3660 - val_accuracy: 0.8686\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8882 - val_loss: 0.3311 - val_accuracy: 0.8812\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8896 - val_loss: 0.3330 - val_accuracy: 0.8814\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3006 - accuracy: 0.8918 - val_loss: 0.3243 - val_accuracy: 0.8834\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2939 - accuracy: 0.8944 - val_loss: 0.3308 - val_accuracy: 0.8814\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2877 - accuracy: 0.8970 - val_loss: 0.3255 - val_accuracy: 0.8820\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2815 - accuracy: 0.8994 - val_loss: 0.3242 - val_accuracy: 0.8812\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2772 - accuracy: 0.9003 - val_loss: 0.3095 - val_accuracy: 0.8854\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2716 - accuracy: 0.9027 - val_loss: 0.3232 - val_accuracy: 0.8860\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2662 - accuracy: 0.9035 - val_loss: 0.3116 - val_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2618 - accuracy: 0.9056 - val_loss: 0.3113 - val_accuracy: 0.8920\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2568 - accuracy: 0.9087 - val_loss: 0.3023 - val_accuracy: 0.8936\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2529 - accuracy: 0.9088 - val_loss: 0.3232 - val_accuracy: 0.8814\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2471 - accuracy: 0.9110 - val_loss: 0.2975 - val_accuracy: 0.8954\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2431 - accuracy: 0.9129 - val_loss: 0.2943 - val_accuracy: 0.8926\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2403 - accuracy: 0.9131 - val_loss: 0.3020 - val_accuracy: 0.8940\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2362 - accuracy: 0.9145 - val_loss: 0.2949 - val_accuracy: 0.8980\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2322 - accuracy: 0.9161 - val_loss: 0.2935 - val_accuracy: 0.8934\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2274 - accuracy: 0.9182 - val_loss: 0.2963 - val_accuracy: 0.8924\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2238 - accuracy: 0.9199 - val_loss: 0.2851 - val_accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n",
    "# sample 편향에 따라 sample_weight 추가 가능(한 샘플은 전문가에 의해 할당, 다른 샘플은 일반인들에 의해 할당)\n",
    "# class 편향에 따라 class_weight 추가 가능(클래스별 등장 횟수가 차이가 심할 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8902fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선으로 확인하기\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c09fe2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 954us/step - loss: 0.3227 - accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3227415382862091, 0.885200023651123]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일반화 오차 추정\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65700e2f",
   "metadata": {},
   "source": [
    "##### 모델 사용해 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3165bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3085162",
   "metadata": {},
   "source": [
    "##### 함수형 API를 사용해 복잡한 모델 만들기\n",
    "- 순차적이지 않은 신경망 : ex) Wide & Deep 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3480ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:]) # 모델의 input 객체 생성, 한 모델은 여러 개의 input을 가질 수 있음\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_) # 만들어지자마자 입력과 함께 함수처럼 호출되는 dense 층\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1) # 첫번째 층의 출력을 전달받아 함수처럼 호출\n",
    "concat = keras.layers.Concatenate()([input_, hidden2]) # concatenate층을 만들고 다시 함수처럼 호출해 두번째 은닉층의 출력과 입력을 연결 ## 주어진 입력으로 바로 호출\n",
    "output = keras.layers.Dense(1)(concat) # 하나의 뉴런과 활성화 함수가 없는 층을 만들고, concatenate 층이 만든 결과를 사용해 호출\n",
    "model = keras.Model(inputs=[input_], outputs=[output]) # 사용할 입력과 출력을 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24544bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 28, 30)       870         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 28, 30)       930         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 58)       0           ['input_1[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 28, 1)        59          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,859\n",
      "Trainable params: 1,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed037e",
   "metadata": {},
   "source": [
    "##### 서브클래싱 API로 동적 모델 만들기\n",
    "- 모델이 반복문을 포함하거나 다양한 크기를 다뤄야 하거나 조건문을 가지는 등 동적 구조를 필요로할 때, 명령형 프로그래밍 스타일을 구현할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6509a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 API를 동적 모델로 구현해본 것\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # 표준 매개변수를 처리(예를 들면, name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_ouput = keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model = WideAndDeepModel()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcfe7f",
   "metadata": {},
   "source": [
    "##### 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536a273",
   "metadata": {},
   "source": [
    "##### 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a73fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매 에포크의 끝에서 checkpoint 호출\n",
    "[...]\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ed7d8",
   "metadata": {},
   "source": [
    "##### 조기종료 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
    "\n",
    "model = keras.models.load_model('my_keras_model.h5') # 최상의 모델로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ealrystopping callback = 일정 에포크 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤\n",
    "# 선택적으로 최상의 모델을 복원할 수 있음\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, elarly_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b3a081",
   "metadata": {},
   "source": [
    "##### 텐서보드를 사용해 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff837113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 로그를 위해 사용할 루트 로그 디렉터리 정의 (중복 방지를 위해 현재 날짜와 시간을 사용해 경로 설정하는 함수 만듦)\n",
    "\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d_%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성과 컴파일\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0db1e0",
   "metadata": {},
   "source": [
    "##### 텐서보드 서버 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5efd52",
   "metadata": {},
   "source": [
    "$ tensorboard  --logdir=./my_logs --host=192.168.56.103 --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8d0b0",
   "metadata": {},
   "source": [
    "##### 신경망 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4222f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일련의 하이퍼파라미터로 케라스 모델을 만들고 컴파일 하는 함수 만들기\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ddc53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1679/2951565612.py:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "# build_model로 KerasRegressor 클래스 객체 만들기\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "# 이렇게 해주면 일반적인 sklearn의 추정기처럼 이 객체를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9951de81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 20:57:07.390542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-29 20:57:07.390572: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-29 20:57:07.390602: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (second): /proc/driver/nvidia/version does not exist\n",
      "2021-11-29 20:57:07.390823: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.6942 - val_loss: 8.2590\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 2s 956us/step - loss: 8.2715 - val_loss: 8.2494\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 2s 949us/step - loss: 8.2698 - val_loss: 8.2459\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 2s 953us/step - loss: 8.2684 - val_loss: 8.2314\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 2s 950us/step - loss: 8.2654 - val_loss: 8.2328\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 2s 956us/step - loss: 8.2635 - val_loss: 8.2471\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 2s 957us/step - loss: 8.2629 - val_loss: 8.2294\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 2s 947us/step - loss: 8.2618 - val_loss: 8.2358\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 2s 956us/step - loss: 8.2602 - val_loss: 8.2300\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 2s 959us/step - loss: 8.2606 - val_loss: 8.2416\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2627 - val_loss: 8.2347\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2621 - val_loss: 8.2526\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2599 - val_loss: 8.2565\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2604 - val_loss: 8.2279\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2605 - val_loss: 8.2525\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2588 - val_loss: 8.2838\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2599 - val_loss: 8.2373\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2601 - val_loss: 8.2287\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 2s 983us/step - loss: 8.2588 - val_loss: 8.2280\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2582 - val_loss: 8.2294\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2592 - val_loss: 8.2378\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 2s 972us/step - loss: 8.2577 - val_loss: 8.2278\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 2s 962us/step - loss: 8.2583 - val_loss: 8.2329\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 2s 969us/step - loss: 8.2567 - val_loss: 8.2391\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2593 - val_loss: 8.2445\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2564 - val_loss: 8.2398\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2572 - val_loss: 8.2373\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2574 - val_loss: 8.2314\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2569 - val_loss: 8.2452\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2552 - val_loss: 8.2364\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 2s 992us/step - loss: 8.2587 - val_loss: 8.2274\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2550 - val_loss: 8.2551\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2566 - val_loss: 8.2276\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2575 - val_loss: 8.2286\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2573 - val_loss: 8.2275\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2581 - val_loss: 8.2536\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2552 - val_loss: 8.2391\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 2s 976us/step - loss: 8.2575 - val_loss: 8.2414\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 2s 985us/step - loss: 8.2571 - val_loss: 8.2295\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2560 - val_loss: 8.2278\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 2s 975us/step - loss: 8.2537 - val_loss: 8.2595\n",
      "313/313 [==============================] - 0s 618us/step - loss: 8.2806\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cde6df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.28061580657959"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d4ac51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 9.4815 - val_loss: 8.2632\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.3083 - val_loss: 8.2443\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2985 - val_loss: 8.2458\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2957 - val_loss: 8.2364\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2946 - val_loss: 8.2355\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2915 - val_loss: 8.2380\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2883 - val_loss: 8.3071\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2912 - val_loss: 8.2380\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2903 - val_loss: 8.2316\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2896 - val_loss: 8.2388\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2892 - val_loss: 8.2389\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2868 - val_loss: 8.2376\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2890 - val_loss: 8.2301\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2889 - val_loss: 8.2338\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2888 - val_loss: 8.2294\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2891 - val_loss: 8.2294\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2882 - val_loss: 8.2352\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2873 - val_loss: 8.2296\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2862 - val_loss: 8.2450\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2878 - val_loss: 8.2352\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2884 - val_loss: 8.2288\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2853 - val_loss: 8.2308\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2883 - val_loss: 8.2285\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2862 - val_loss: 8.2407\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2859 - val_loss: 8.2310\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2868 - val_loss: 8.2341\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2851 - val_loss: 8.2290\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2872 - val_loss: 8.2361\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2871 - val_loss: 8.2302\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2845 - val_loss: 8.2417\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2857 - val_loss: 8.2308\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2859 - val_loss: 8.2430\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2876 - val_loss: 8.2282\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2876 - val_loss: 8.2321\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2850 - val_loss: 8.2281\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2861 - val_loss: 8.2279\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2851 - val_loss: 8.2288\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2859 - val_loss: 8.2285\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2852 - val_loss: 8.2341\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2859 - val_loss: 8.2286\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2863 - val_loss: 8.2288\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2848 - val_loss: 8.2404\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2855 - val_loss: 8.2464\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2874 - val_loss: 8.2278\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2852 - val_loss: 8.2285\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2846 - val_loss: 8.2277\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2830 - val_loss: 8.2280\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2837 - val_loss: 8.2278\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2861 - val_loss: 8.2461\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2855 - val_loss: 8.2288\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2845 - val_loss: 8.2396\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2856 - val_loss: 8.2280\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2857 - val_loss: 8.2280\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2853 - val_loss: 8.2283\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2841 - val_loss: 8.2302\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2856 - val_loss: 8.2315\n",
      "573/573 [==============================] - 0s 643us/step - loss: 8.1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 9.5081 - val_loss: 8.2755\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2581 - val_loss: 8.2525\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2483 - val_loss: 8.2419\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2460 - val_loss: 8.2395\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2430 - val_loss: 8.2389\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2380 - val_loss: 8.2333\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2396 - val_loss: 8.2331\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2387 - val_loss: 8.2316\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2355 - val_loss: 8.2406\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2369 - val_loss: 8.2311\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2373 - val_loss: 8.2362\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2312 - val_loss: 8.2321\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2355 - val_loss: 8.2298\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2351 - val_loss: 8.2323\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2360 - val_loss: 8.2383\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2363 - val_loss: 8.2296\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2347 - val_loss: 8.2339\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2352 - val_loss: 8.2411\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2355 - val_loss: 8.2296\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2333 - val_loss: 8.2356\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2330 - val_loss: 8.2294\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2341 - val_loss: 8.2398\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2343 - val_loss: 8.2322\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2328 - val_loss: 8.2286\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2333 - val_loss: 8.2323\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2328 - val_loss: 8.2329\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2328 - val_loss: 8.2409\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2343 - val_loss: 8.2286\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2342 - val_loss: 8.2286\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2327 - val_loss: 8.2282\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2332 - val_loss: 8.2349\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2336 - val_loss: 8.2294\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2326 - val_loss: 8.2284\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2330 - val_loss: 8.2292\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2319 - val_loss: 8.2543\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2341 - val_loss: 8.2392\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2329 - val_loss: 8.2307\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2320 - val_loss: 8.2405\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2335 - val_loss: 8.2290\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2311 - val_loss: 8.2292\n",
      "573/573 [==============================] - 0s 694us/step - loss: 8.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 9.4485 - val_loss: 8.2759\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2722 - val_loss: 8.2481\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2618 - val_loss: 8.2407\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2578 - val_loss: 8.2405\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2544 - val_loss: 8.2352\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2535 - val_loss: 8.2334\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2505 - val_loss: 8.2326\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2488 - val_loss: 8.2406\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2503 - val_loss: 8.2420\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2483 - val_loss: 8.2313\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2462 - val_loss: 8.2345\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2489 - val_loss: 8.2304\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2479 - val_loss: 8.2299\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2486 - val_loss: 8.2303\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2455 - val_loss: 8.2304\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2476 - val_loss: 8.2306\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2471 - val_loss: 8.2304\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2465 - val_loss: 8.2445\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2474 - val_loss: 8.2342\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2478 - val_loss: 8.2332\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2458 - val_loss: 8.2295\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2452 - val_loss: 8.2309\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2478 - val_loss: 8.2288\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2453 - val_loss: 8.2288\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2448 - val_loss: 8.2311\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2450 - val_loss: 8.2343\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2468 - val_loss: 8.2302\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2467 - val_loss: 8.2306\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2453 - val_loss: 8.2376\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2455 - val_loss: 8.2418\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2459 - val_loss: 8.2304\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2453 - val_loss: 8.2285\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2449 - val_loss: 8.2284\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2474 - val_loss: 8.2320\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2465 - val_loss: 8.2282\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2446 - val_loss: 8.2456\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2466 - val_loss: 8.2280\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2446 - val_loss: 8.2289\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2463 - val_loss: 8.2299\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2447 - val_loss: 8.2289\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2464 - val_loss: 8.2279\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2459 - val_loss: 8.2365\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2445 - val_loss: 8.2280\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2452 - val_loss: 8.2301\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2439 - val_loss: 8.2315\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2468 - val_loss: 8.2278\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2459 - val_loss: 8.2298\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2447 - val_loss: 8.2542\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2461 - val_loss: 8.2279\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2458 - val_loss: 8.2348\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2442 - val_loss: 8.2430\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2469 - val_loss: 8.2304\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2452 - val_loss: 8.2282\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2447 - val_loss: 8.2359\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2438 - val_loss: 8.2305\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2441 - val_loss: 8.2357\n",
      "573/573 [==============================] - 0s 668us/step - loss: 8.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.6146 - val_loss: 8.2373\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3185 - val_loss: 8.2939\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3082 - val_loss: 8.2435\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3065 - val_loss: 8.2794\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3037 - val_loss: 8.2316\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3093 - val_loss: 8.2375\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3038 - val_loss: 8.2596\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3006 - val_loss: 8.2500\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.3020 - val_loss: 8.2287\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2959 - val_loss: 8.2395\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2995 - val_loss: 8.2318\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2962 - val_loss: 8.2336\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2953 - val_loss: 8.2347\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2896 - val_loss: 8.2311\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2937 - val_loss: 8.2307\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2943 - val_loss: 8.2678\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2936 - val_loss: 8.2464\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2929 - val_loss: 8.2419\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2933 - val_loss: 8.2291\n",
      "573/573 [==============================] - 1s 876us/step - loss: 8.1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.5812 - val_loss: 8.2531\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2646 - val_loss: 8.2503\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2541 - val_loss: 8.2387\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2541 - val_loss: 8.2696\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2529 - val_loss: 8.2509\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2535 - val_loss: 8.2297\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2509 - val_loss: 8.2319\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2468 - val_loss: 8.2603\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2447 - val_loss: 8.2288\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2452 - val_loss: 8.2309\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2429 - val_loss: 8.2489\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2401 - val_loss: 8.2475\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2411 - val_loss: 8.2343\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2420 - val_loss: 8.2333\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2421 - val_loss: 8.2587\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2430 - val_loss: 8.2299\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2360 - val_loss: 8.2472\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2399 - val_loss: 8.2354\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2382 - val_loss: 8.2482\n",
      "573/573 [==============================] - 1s 850us/step - loss: 8.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 8.6032 - val_loss: 8.2356\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2743 - val_loss: 8.2317\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2692 - val_loss: 8.2417\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2697 - val_loss: 8.2894\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2645 - val_loss: 8.2345\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2629 - val_loss: 8.2511\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2633 - val_loss: 8.2313\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2619 - val_loss: 8.2403\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2565 - val_loss: 8.3052\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2579 - val_loss: 8.2306\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2580 - val_loss: 8.2303\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2558 - val_loss: 8.2517\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2546 - val_loss: 8.2475\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2568 - val_loss: 8.2316\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2524 - val_loss: 8.2655\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2534 - val_loss: 8.2281\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2510 - val_loss: 8.2275\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2525 - val_loss: 8.2273\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2559 - val_loss: 8.2371\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2502 - val_loss: 8.2484\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2516 - val_loss: 8.2306\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2482 - val_loss: 8.3048\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2454 - val_loss: 8.2367\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2480 - val_loss: 8.2365\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2505 - val_loss: 8.2828\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2471 - val_loss: 8.2271\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2505 - val_loss: 8.2299\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2499 - val_loss: 8.2278\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2446 - val_loss: 8.2275\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2462 - val_loss: 8.2412\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2467 - val_loss: 8.2301\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2499 - val_loss: 8.2317\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2472 - val_loss: 8.2284\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2492 - val_loss: 8.2314\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2467 - val_loss: 8.2271\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2481 - val_loss: 8.2411\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2478 - val_loss: 8.2339\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2439 - val_loss: 8.2287\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2450 - val_loss: 8.2305\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2473 - val_loss: 8.2286\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2440 - val_loss: 8.2300\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2441 - val_loss: 8.2313\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2471 - val_loss: 8.2318\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2468 - val_loss: 8.2276\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2444 - val_loss: 8.2270\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2474 - val_loss: 8.2357\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.2460 - val_loss: 8.2372\n",
      "Epoch 48/100\n",
      "1129/1146 [============================>.] - ETA: 0s - loss: 8.2458"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1679/3582834997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[1;32m     14\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 726\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    749\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 751\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3235\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3237\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3238\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3239\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터가 많으므로 그리드 탐색보다는 랜덤 탐색을 사용하는 것이 좋음\n",
    "# 은닉층 개수, 뉴런 개수, 학습률을 사용하여 하이퍼파라미터 탐색 수행\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden':[0,1,2,3],\n",
    "    'n_neurons':np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d93138cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1679/155825779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 훈련이 끝나면 최상의 하이퍼파라미터와 훈련된 케라스 모델을 얻을 수 있음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# 훈련이 끝나면 최상의 하이퍼파라미터와 훈련된 케라스 모델을 얻을 수 있음\n",
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1c4c9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1679/1173820217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c026ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1679/1400620604.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보통 실전에서는 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고\n",
    "# 그런다음 과대적합되지 않도록 조기 종료나 규제 기법을 사용하는 것이 간단하고 효과적임\n",
    "# 일반적으로 층의 뉴런 수보다 층 수를 늘리는 쪽이 이득이 많음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
