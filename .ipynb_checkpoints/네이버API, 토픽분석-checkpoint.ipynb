{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296692e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import konlpy\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f94ee",
   "metadata": {},
   "source": [
    "# 워드 클라우드 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9c2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(text, ntags=50): #상위 50개 출력\n",
    "    spliter = Okt()\n",
    "    nouns = spliter.nouns(text)\n",
    "    count = Counter(nouns)\n",
    "    return dict(count.most_common(ntags))\n",
    "\n",
    "def clean_str(s):\n",
    "    hangul = re.compile('[^ㄱ-ㅎ|가-힣]+')\n",
    "    s = hangul.sub(r' ',s)\n",
    "    cp = re.compile('['\n",
    "                    u'\\U00010000-\\U0010FFFF'\n",
    "                   ']+', flags=re.UNICODE\n",
    "                   )\n",
    "    s = cp.sub(r'', s)\n",
    "    return s.strip()\n",
    "\n",
    "def Wordcloud(data, savename, maskname=''):\n",
    "    if maskname == '':\n",
    "        wc = WordCloud(font_path='font/BMDOHYEON_ttf.ttf', background_color='white', max_font_size=60, colormap='copper')\n",
    "    else:\n",
    "        maskimg = np.array(Image.open(maskname))\n",
    "        for i in range(len(maskimg)):\n",
    "            for j in range(len(maskimg[i])):\n",
    "                if maskimg[i][j]== 0:\n",
    "                    maskimg[i][j] = 255\n",
    "        wc = WordCloud(font_path='font/BMDOHYEON_ttf.ttf', background_color='white', mask=maskimg, max_font_size=60, colormap='copper')\n",
    "    wc.generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(wc)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def get_blog():\n",
    "\n",
    "    client_id = \"4FdY0qL5azIJ4BXVjUal\"\n",
    "    client_secret = \"Ylgg4Oh_FN\"\n",
    "    search = input('검색어를 입력하세요 : ')\n",
    "    blog_data = pd.DataFrame()\n",
    "    encText = urllib.parse.quote(search)\n",
    "    title = list()\n",
    "    description = list()\n",
    "    adress = list()\n",
    "\n",
    "    for i in range(1, 1000, 100):\n",
    "        try:\n",
    "            url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + '&display=100'+'&sort=sim'+f'&start={i}' # json 결과\n",
    "            # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "            request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            rescode = response.getcode()\n",
    "\n",
    "            if(rescode==200):\n",
    "                response_body = response.read().decode('utf-8')\n",
    "                response_body1 = json.loads(str(response_body))\n",
    "                for i in response_body1['items']:\n",
    "                    hangul = re.compile('[^ ㄱ-ㅎ|가-힣]+')\n",
    "                    title.append(hangul.sub(r'', i['title']))\n",
    "                    description.append(hangul.sub(r'', i['description']))\n",
    "                    adress.append(i['link'])\n",
    "            else:\n",
    "                print(\"Error Code:\" + rescode)\n",
    "\n",
    "        except:\n",
    "            print('Error')\n",
    "\n",
    "    blog_data['title'] = title\n",
    "    blog_data['description']= description\n",
    "    blog_data['adress'] = adress\n",
    "    blog_data.to_csv('data/{0}블로그 데이터.txt'.format(search), mode='a', header=True, index=True)\n",
    "    \n",
    "def get_cafe():\n",
    "\n",
    "    client_id = \"4FdY0qL5azIJ4BXVjUal\"\n",
    "    client_secret = \"Ylgg4Oh_FN\"\n",
    "    search = input('검색어를 입력하세요 : ')\n",
    "    cafe_data = pd.DataFrame()\n",
    "    encText = urllib.parse.quote(search)\n",
    "    title = list()\n",
    "    description = list()\n",
    "    adress = list()\n",
    "\n",
    "    for i in range(1, 1000, 100):\n",
    "        try:\n",
    "            url = \"https://openapi.naver.com/v1/search/cafearticle?query=\" + encText + '&display=100'+'&sort=sim'+f'&start={i}' # json 결과\n",
    "            # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "            request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            rescode = response.getcode()\n",
    "\n",
    "            if(rescode==200):\n",
    "                response_body = response.read().decode('utf-8')\n",
    "                response_body1 = json.loads(str(response_body))\n",
    "                for i in response_body1['items']:\n",
    "                    hangul = re.compile('[^ ㄱ-ㅎ|가-힣]+')\n",
    "                    title.append(hangul.sub(r'', i['title']))\n",
    "                    description.append(hangul.sub(r'', i['description']))\n",
    "                    adress.append(i['link'])\n",
    "            else:\n",
    "                print(\"Error Code:\" + rescode)\n",
    "\n",
    "        except:\n",
    "            print('Error')\n",
    "\n",
    "    cafe_data['title'] = title\n",
    "    cafe_data['description']= description\n",
    "    cafe_data['adress'] = adress\n",
    "\n",
    "    cafe_data.to_csv('data/{0}카페 데이터.txt'.format(search), mode='a', header=True, index=True)\n",
    "    \n",
    "def get_news():\n",
    "    client_id = \"4FdY0qL5azIJ4BXVjUal\"\n",
    "    client_secret = \"Ylgg4Oh_FN\"\n",
    "    search = input('검색어를 입력하세요 : ')\n",
    "    news_data = pd.DataFrame()\n",
    "    encText = urllib.parse.quote(search)\n",
    "    title = list()\n",
    "    description = list()\n",
    "    adress = list()\n",
    "\n",
    "    for i in range(1, 1000, 100):\n",
    "        try:\n",
    "            url = \"https://openapi.naver.com/v1/search/news?query=\" + encText + '&display=100'+'&sort=sim'+f'&start={i}' # json 결과\n",
    "            # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "            request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            rescode = response.getcode()\n",
    "\n",
    "            if(rescode==200):\n",
    "                response_body = response.read().decode('utf-8')\n",
    "                response_body1 = json.loads(str(response_body))\n",
    "                for i in response_body1['items']:\n",
    "                    hangul = re.compile('[^ ㄱ-ㅎ|가-힣]+')\n",
    "                    title.append(hangul.sub(r'', i['title']))\n",
    "                    description.append(hangul.sub(r'', i['description']))\n",
    "                    adress.append(i['link'])\n",
    "            else:\n",
    "                print(\"Error Code:\" + rescode)\n",
    "\n",
    "        except:\n",
    "            print('Error')\n",
    "\n",
    "    news_data['title'] = title\n",
    "    news_data['description']= description\n",
    "    news_data['adress'] = adress\n",
    "    news_data.to_csv('data/{0}뉴스 데이터.txt'.format(search), mode='a', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata = ''\n",
    "for i in df1['description']:\n",
    "    textdata = textdata + ' ' + i\n",
    "\n",
    "tresult = get_tags(textdata, ntags=200)\n",
    "print(tresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99e0ea",
   "metadata": {},
   "source": [
    "# 네이버 블로그 파일로(간략ver) 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d973b270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4428352d",
   "metadata": {},
   "source": [
    "# 네이버 카페 파일(간략ver)로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b854469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff82ee37",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 파일(간략ver)로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fefd5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d850ce46",
   "metadata": {},
   "source": [
    "# 주소만 뽑아와서 상세 데이터 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbd457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_detail():\n",
    "    client_id = \"4FdY0qL5azIJ4BXVjUal\"\n",
    "    client_secret = \"Ylgg4Oh_FN\"\n",
    "    search = input('검색어를 입력하세요 : ')\n",
    "    blog_data = pd.DataFrame()\n",
    "    encText = urllib.parse.quote(search)\n",
    "    adress = list()\n",
    "\n",
    "    for i in range(1, 1000, 100):\n",
    "        try:\n",
    "            url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + '&display=100'+'&sort=sim'+f'&start={i}' # json 결과\n",
    "            # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "            request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            rescode = response.getcode()\n",
    "\n",
    "            if(rescode==200):\n",
    "                response_body = response.read().decode('utf-8')\n",
    "                response_body1 = json.loads(str(response_body))\n",
    "                for i in response_body1['items']:\n",
    "                    hangul = re.compile('[^ ㄱ-ㅎ|가-힣]+')\n",
    "                    adress.append(i['link'])\n",
    "            else:\n",
    "                print(\"Error Code:\" + rescode)\n",
    "\n",
    "        except:\n",
    "            print('Error')\n",
    "\n",
    "    blog_data['adress'] = adress\n",
    "    blog_data.to_csv('data/{0}블로그 주소목록.txt'.format(search), mode='a', header=True, index=True)\n",
    "    \n",
    "    df = pd.read_csv('data/{0}블로그 주소목록.txt'.format(search))\n",
    "    df['adress'] = df['adress'].str.replace('://', '://m.')\n",
    "    for i in df['adress']:\n",
    "        try:\n",
    "            page = requests.get(f'{i}')\n",
    "            html = page.text\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            data1 = soup.find_all('div', {'class':'se-component-content'})\n",
    "            title = soup.find('span', {'class':'se-fs-fs32 se-ff-nanumsquare'}).text\n",
    "            data3 = soup.find('div', {'class':'se-main-container'}).text\n",
    "            contents = re.sub('[^A-Za-z0-9가-힣- -.]', '', data3)\n",
    "            contents = contents.replace('\\r', ' ')\n",
    "            naverblog = [contents]\n",
    "            naverblog = pd.DataFrame(naverblog)\n",
    "            naverblog.to_csv('data/{0}블로그 상세 데이터.txt'.format(search), mode='a', header=True, index=True)\n",
    "        except:\n",
    "            print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요 : adsp후기\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "get_blog_detail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be20b3",
   "metadata": {},
   "source": [
    "# 뽑아온 주소로 상세 데이터 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7fb2557",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5e3bd4bac4dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'se-component-content'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'se-fs-fs32 se-ff-nanumsquare'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mdata3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'se-main-container'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^A-Za-z0-9가-힣- -.]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/도라에몽블로그 주소목록.txt')\n",
    "df['adress'] = df['adress'].str.replace('://', '://m.')\n",
    "for i in df['adress']:\n",
    "        page = requests.get(f'{i}')\n",
    "        html = page.text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        data1 = soup.find_all('div', {'class':'se-component-content'})\n",
    "        title = soup.find('span', {'class':'se-fs-fs32 se-ff-nanumsquare'}).text\n",
    "        data3 = soup.find('div', {'class':'se-main-container'}).text\n",
    "        contents = re.sub('[^A-Za-z0-9가-힣- -.]', '', data3)\n",
    "        contents = contents.replace('\\r', ' ')\n",
    "        naverblog = [title, contents]\n",
    "        naverblog = pd.DataFrame(naverblog)\n",
    "        df.to_csv('data/도라에몽블로그 상세 데이터.txt', mode='a', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "815ea81c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9d012a8d8764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/도라에몽블로그 주소목록.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{i}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/도라에몽블로그 주소목록.txt')\n",
    "for i in df['adress']:\n",
    "    page = requests.get(f'{i}')\n",
    "\n",
    "    print(page)\n",
    "\n",
    "\n",
    "#     html = page.text\n",
    "#     soup = BeautifulSoup(html, 'lxml')\n",
    "#     data1 = soup.find_all('div', {'class':'se-component-content'})\n",
    "#     title = soup.find('span', {'class':'se-fs-fs32 se-ff-nanumsquare'}).text\n",
    "#     data3 = soup.find('div', {'class':'se-main-container'}).text\n",
    "#     contents = re.sub('[^A-Za-z0-9가-힣- -.]', '', data3)\n",
    "#     contents = contents.replace('\\r', ' ')\n",
    "#     naverblog = [title, contents]\n",
    "#     naverblog = pd.DataFrame(naverblog)\n",
    "#     blog_data.to_csv('data/{0}블로그 상세 데이터.txt'.format(search), mode='a', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fb1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
